{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xvgVOP4697q",
        "colab_type": "text"
      },
      "source": [
        "# Simple GAN implemented in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VB9mLDSiGqu",
        "colab_type": "text"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMJHJUvniGOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST98Dm2K70Va",
        "colab_type": "text"
      },
      "source": [
        "## Imports first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY-tyZAGQdrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image as IImage\n",
        "from PIL import Image\n",
        "from keras.layers import *\n",
        "from keras.models import Model, Sequential\n",
        "from keras.datasets import mnist\n",
        "import random\n",
        "import operator\n",
        "from functools import reduce\n",
        "from scipy.signal import savgol_filter\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2w6o1bvey2e",
        "colab_type": "text"
      },
      "source": [
        "## Load and prepare MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igTbNqVXe1RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "image_shape = (28, 28, 1)\n",
        "quarter_image_shape = ()\n",
        "half_image_shape = ()\n",
        "if image_shape[2] != 1:\n",
        "  quarter_image_shape = (image_shape[0] // 4, image_shape[1] // 4, image_shape[2] // 4)\n",
        "  half_image_shape = (image_shape[0] // 2, image_shape[1] // 2, image_shape[2] // 2)\n",
        "else:\n",
        "  quarter_image_shape = (image_shape[0] // 4, image_shape[1] // 4, 1)\n",
        "  half_image_shape = (image_shape[0] // 2, image_shape[1] // 2, 1)\n",
        "  \n",
        "x_real = np.concatenate((x_train, x_test), axis=0)\n",
        "y_real = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "def preprocess_imgs(x):\n",
        "  x = x.reshape((x.shape[0],) + image_shape)\n",
        "  return x / 255\n",
        "\n",
        "\n",
        "def preprocess_labels(y):\n",
        "  return np.ones(y.shape)\n",
        "\n",
        "x_real = preprocess_imgs(x_real)\n",
        "y_real = preprocess_labels(y_real)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5wUL8fv671g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_m_noise_images_of_n_size(m: int, n: int):\n",
        "  mean = 0\n",
        "  var = 0.1\n",
        "  sigma = var**0.5\n",
        "  return np.random.normal(mean,sigma,(m, n))\n",
        "\n",
        "batch_size = 256\n",
        "generator_input_length = np.prod(quarter_image_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF_9l0fB8MkF",
        "colab_type": "text"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZOGJSLmpjAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(use_conv=False):\n",
        "  generator = Sequential()\n",
        "  \n",
        "  if use_conv:\n",
        "\n",
        "    generator.add(\n",
        "      Dense(np.prod(quarter_image_shape), input_shape=(np.prod(quarter_image_shape),))\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      BatchNormalization()\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      LeakyReLU()\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      Reshape(quarter_image_shape, input_shape=(np.prod(quarter_image_shape),)) \n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      Conv2DTranspose(1, kernel_size=2, strides=2)\n",
        "    )\n",
        "\n",
        "    generator.add(Flatten())\n",
        "\n",
        "    generator.add(\n",
        "      Dense(np.prod(half_image_shape))\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      BatchNorwmalization()\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      LeakyReLU()\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      Reshape(half_image_shape) \n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      Conv2DTranspose(1, kernel_size=2, strides=2)\n",
        "    )\n",
        "  else:\n",
        "    generator.add(\n",
        "      Dense(np.prod(quarter_image_shape), input_shape=(np.prod(quarter_image_shape),))\n",
        "    )\n",
        "    \n",
        "    generator.add(\n",
        "      BatchNormalization()\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      LeakyReLU()\n",
        "    )\n",
        "    \n",
        "    generator.add(\n",
        "      Dense(np.prod(half_image_shape))\n",
        "    )\n",
        "    \n",
        "    generator.add(\n",
        "      BatchNormalization()\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      LeakyReLU()\n",
        "    )\n",
        "    \n",
        "    generator.add(\n",
        "      Dense(np.prod(image_shape))\n",
        "    )\n",
        "    \n",
        "    generator.add(\n",
        "      BatchNormalization()\n",
        "    )\n",
        "\n",
        "    generator.add(\n",
        "      LeakyReLU()\n",
        "    )\n",
        "    \n",
        "    generator.add(\n",
        "      Reshape(image_shape) \n",
        "    )\n",
        "\n",
        "  generator.compile(\n",
        "    'RMSProp', 'mse', ['acc']\n",
        "  )\n",
        "  \n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa26fQH2eN31",
        "colab_type": "code",
        "outputId": "74bec9e7-afc2-42d4-dc15-359c1c8be480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# Create a model which will determine and train image recognition\n",
        "discriminator = Sequential()\n",
        "discriminator.add(\n",
        "    Dense(10, activation='relu', input_shape=image_shape)\n",
        ")\n",
        "discriminator.add((Dropout(0.8)))\n",
        "discriminator.add(\n",
        "    LeakyReLU(alpha=0.1)\n",
        ")\n",
        "discriminator.add((Dropout(0.8)))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(128, activation='relu'))\n",
        "discriminator.add(Dense(1, activation='sigmoid'))\n",
        "discriminator.compile(\n",
        "  'RMSProp', 'binary_crossentropy', ['acc']\n",
        ")\n",
        "\n",
        "# Create a model which will generate images and \n",
        "# try to make discriminator give wrong answers\n",
        "\n",
        "generator = build_generator(use_conv=False)\n",
        "\n",
        "# Create a model which will train generator\n",
        "discriminator.trainable = False\n",
        "gen_and_disc = Sequential()\n",
        "gen_and_disc.add(generator)\n",
        "gen_and_disc.add(discriminator)\n",
        "gen_and_disc.compile(\n",
        "  'RMSProp', 'binary_crossentropy', ['acc']\n",
        ")\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 07:50:42.076173 140491410323328 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 49)                2450      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 49)                196       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 49)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 196)               9800      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 196)               784       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 196)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 784)               154448    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 170,814\n",
            "Trainable params: 168,756\n",
            "Non-trainable params: 2,058\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPFV_iX29CH-",
        "colab_type": "text"
      },
      "source": [
        "## Stack models and train them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ-SSjs-9DgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1000000\n",
        "di = 10  # Train discriminator on batch every dith epoch\n",
        "gadi = 1  # Train generator on batch every gadith epoch\n",
        "\n",
        "\n",
        "#  this function shuffles xs and ys\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "def print_every_nth(i, n):\n",
        "  if not (i % n):\n",
        "    print(\"EPOCH %d\" % i)\n",
        "  \n",
        "disc_history = {\n",
        "  'acc': [],\n",
        "  'loss': []\n",
        "}\n",
        "\n",
        "gad_history = {\n",
        "  'acc': [],\n",
        "  'loss': []\n",
        "}\n",
        "  \n",
        "for i in range(EPOCHS):\n",
        "  if not (i % 100):\n",
        "    print(\"EPOCH %d\" % i)\n",
        "    plt.figure()\n",
        "    img = generator.predict(\n",
        "      make_m_noise_images_of_n_size(1, generator_input_length)\n",
        "      )[0]\n",
        "    if image_shape[2] == 1:\n",
        "      img = np.reshape(img, image_shape[:2])\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "  #  train discriminator on batch with 50% generated and 50% real\n",
        "  if not (i % di):\n",
        "    x_real_temp = x_real[random.sample(range(0, len(x_real)), batch_size // 2)]\n",
        "    y_real_temp = y_real[random.sample(range(0, len(y_real)), batch_size // 2)]\n",
        "\n",
        "\n",
        "    x_fake, y_fake = generator.predict(\n",
        "        make_m_noise_images_of_n_size(batch_size // 2, generator_input_length)\n",
        "    ), np.zeros(batch_size // 2)\n",
        "\n",
        "    x, y = unison_shuffled_copies(np.concatenate((x_real_temp, x_fake)), np.concatenate((y_real_temp, y_fake)))\n",
        "\n",
        "    disc_hist = discriminator.train_on_batch(x, y)\n",
        "    disc_history['acc'].append(disc_hist[1])\n",
        "    disc_history['loss'].append(disc_hist[0])\n",
        "  else:\n",
        "    disc_history['acc'].append(disc_history['acc'][-1])\n",
        "    disc_history['loss'].append(disc_history['loss'][-1])\n",
        "  #  train generator\n",
        "  if not (i % gadi):\n",
        "    x, y = make_m_noise_images_of_n_size(batch_size, generator_input_length), np.ones(batch_size)\n",
        "    gad_hist = gen_and_disc.train_on_batch(x, y)\n",
        "    gad_history['acc'].append(gad_hist[1])\n",
        "    gad_history['loss'].append(gad_hist[0])\n",
        "  else:\n",
        "    gad_history['acc'].append(gad_history['acc'][-1])\n",
        "    gad_history['loss'].append(gad_history['loss'][-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2coT3yVKuK7",
        "colab_type": "text"
      },
      "source": [
        "## Plot losses and accuraccy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S21JjI4-Kvwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Loss while training generator and discriminator\")\n",
        "plt.plot(gad_history['loss'], color='r')\n",
        "plt.plot(disc_history['loss'], color='b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceUfB5emLb2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuraccy while training generator and discriminator\")\n",
        "plt.plot(gad_history['acc'], color='r')\n",
        "plt.plot(disc_history['acc'], color='b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qDO1wfiuKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuraccy while training generator and discriminator\")\n",
        "Y_gad = savgol_filter(gad_history['acc'], 101, 3)\n",
        "Y_disc = savgol_filter(disc_history['acc'], 101, 3)\n",
        "plt.plot(Y_gad, color='r')\n",
        "plt.plot(Y_disc, color='b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8LsH0-YIeUP",
        "colab_type": "text"
      },
      "source": [
        "## Show what generator can do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MLJlD55IgZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = generator.predict(\n",
        "      make_m_noise_images_of_n_size(1, generator_input_length)\n",
        "  )[0]\n",
        "if image_shape[2] == 1:\n",
        "  img = np.reshape(img, image_shape[:2])\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}